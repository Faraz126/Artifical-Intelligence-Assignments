{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BxLlLYPvWz5r"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S7JB6EcwWz6J"
   },
   "outputs": [],
   "source": [
    "class NaiveBayes():\n",
    "    def __init__(self):\n",
    "        self.data_set = None #original dataset\n",
    "        self.train_data_set = None\n",
    "        self.test_data_set = None\n",
    "        self.probabilities = dict()\n",
    "\n",
    "    def probability(self, occurance, total, total_categories, laplacian = True):\n",
    "        if laplacian:\n",
    "            alpha = 1\n",
    "            return (alpha + occurance) / ((alpha * total_categories) + total)\n",
    "        else:\n",
    "            return (occurance) / total\n",
    "\n",
    "    def learn(self, input, output):\n",
    "        self.trainX = input.toarray()\n",
    "        self.trainY = output.array\n",
    "        self.labels = list(output.value_counts().index)\n",
    "        self.labels_prob = {self.labels[key]:self.probability(value, len(output), len(self.labels)) for key,value in enumerate(output.value_counts())}\n",
    "        no_of_columns = self.trainX.shape[1]\n",
    "        self.no_of_columns = no_of_columns\n",
    "        self.learned_prob = np.zeros((len(self.labels), self.trainX.shape[1], 2)) #matrix to hold all probabilities. matrix_ij stores probability of word j given label i\n",
    "        for i in range(len(self.labels)):\n",
    "            print(\"Learning probablities for\", self.labels[i] )\n",
    "            cur_label = self.labels[i]\n",
    "            indices = np.where(self.trainY == cur_label)[0] #finding indicies where label i is found\n",
    "            total = len(indices) #total cases of label i\n",
    "            freq = [np.unique(self.trainX[indices,i], return_counts = True)[1] for i in range(no_of_columns)] #stores a list of counts of each word\n",
    "            freq_array = np.zeros((no_of_columns, 2))\n",
    "            freq_array = np.array([(self.probability(tup[0], total, 2), self.probability(sum(tup[1:]), total, 2)) for tup in freq])\n",
    "            self.learned_prob[i] = freq_array #assigning the all probabities of all the words occuring (and not occuring) given label i\n",
    "\n",
    "\n",
    "    def classify(self, inputs):\n",
    "        input_mat = inputs.toarray()\n",
    "        predictions = np.zeros((len(self.labels), input_mat.shape[0])) #the matrix to hold all probabilities. matrix_ij represents probablity of class i given sentence j\n",
    "        input_mat[np.where(input_mat > 1)[0]] = 1 #converting all to binary case\n",
    "        no_rows = np.zeros(self.no_of_columns)\n",
    "        no_cols = np.zeros(self.no_of_columns)\n",
    "        no_cols = range(self.no_of_columns)\n",
    "        predicted_vals = []\n",
    "        for i, label in enumerate(self.labels):\n",
    "            print(\"computing probabilites for\", label)\n",
    "            no_rows = i\n",
    "            prod_label = self.labels_prob[label] \n",
    "            for row_num in range(len(input_mat)):\n",
    "                probs = self.learned_prob[no_rows, no_cols, input_mat[row_num]]\n",
    "                # P(i_label | given sentence) = P(all words | label) * P(i_label)\n",
    "                predictions[i, row_num] = np.prod(probs) * prod_label\n",
    "        print('prediction done')\n",
    "        for i in range((input_mat.shape[0])):\n",
    "            min_ind = np.where(predictions[:,i] == np.amax(predictions[:,i]))[0] #finding the max\n",
    "            predicted_vals.append(self.labels[min_ind[0]])\n",
    "\n",
    "        return predicted_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wxUPkODGWz6c"
   },
   "outputs": [],
   "source": [
    "def load_file(fileName):\n",
    "    dataset = pd.read_csv(fileName, header=0, sep=\",\", encoding=\"unicode_escape\", error_bad_lines = False)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y5PbJLbFWz6v"
   },
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    count_vectorizer = CountVectorizer(binary = True, stop_words= 'english')\n",
    "    data = count_vectorizer.fit_transform(data)\n",
    "    #tfidf_data = TfidfTransformer(use_idf=False).fit_transform(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XhGeoVMJWz6-"
   },
   "outputs": [],
   "source": [
    "def learn_model(data,target):\n",
    "    classifier = NaiveBayes()\n",
    "    classifier.learn(data, target)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j7g_6wG_Wz7L"
   },
   "outputs": [],
   "source": [
    "def classify(classifier, testdata):\n",
    "    predicted_val= classifier.classify(testdata)\n",
    "    return predicted_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gx9TN64uWz7a"
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(actual, predicted):\n",
    "    labels = list(actual.value_counts().index)\n",
    "    matrix = np.zeros((len(labels), len(labels)))\n",
    "    for index, val in enumerate(actual.array):\n",
    "        predicted_val = predicted[index]\n",
    "        matrix[labels.index(val), labels.index(predicted_val)] += 1\n",
    "    return matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kn_UzMmLWz7o"
   },
   "outputs": [],
   "source": [
    "def precision(TP, FP, TN, FN):\n",
    "    if (TP + FP) == 0:\n",
    "        return 0\n",
    "    return TP / (TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xxZM_XnmWz72"
   },
   "outputs": [],
   "source": [
    "def recall(TP, FP, TN, FN):\n",
    "    if (TP + FN) == 0:\n",
    "        return 0\n",
    "    return TP / (TP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P2I42yB4W0Cq"
   },
   "outputs": [],
   "source": [
    "def f1score(p, r):\n",
    "    if (r + p) == 0:\n",
    "        return 0\n",
    "    return 2*(r * p) / (r + p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yi-IqpsGW0C9"
   },
   "outputs": [],
   "source": [
    "def evaluate(actual_class, predicted_class):\n",
    "    accuracy = 0\n",
    "    mat = confusion_matrix(actual_class, predicted_class) \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1 = []\n",
    "    accurate = 0\n",
    "    counts = actual_class.value_counts() #counts of labels in the test set.\n",
    "    \n",
    "    print(' '.join(list(actual_class.value_counts().index)))\n",
    "    print(mat)\n",
    "    \n",
    "    for i in range(mat.shape[0]):\n",
    "        weight = counts[i] / np.sum(counts) #frequency of label\n",
    "        TP = mat[i,i]\n",
    "        FP = np.sum(mat[:,i]) - TP\n",
    "        FN = np.sum(mat[i,:]) - TP\n",
    "        TN = np.sum(mat) - TP - FP - FN\n",
    "        precisions.append(precision(TP, FP, TN, FN) * weight) #storing weighted precision\n",
    "        recalls.append(recall(TP, FP, TN, FN) * weight)\n",
    "        f1.append(f1score(precisions[i]/weight, recalls[i]/weight) * weight) #dividing by weight, cos F1 is supposed to take precision, and not weight precision.\n",
    "        accurate += TP\n",
    "    \n",
    "    print(\"The precision score is :\", sum(precisions))\n",
    "    print(\"The recall score is :\", sum(recalls))\n",
    "    print(\"The F1 score is :\", sum(f1))\n",
    "    print(\"The accuracy score is :\", accurate/len(predicted_class))\n",
    "    \n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "pkZbZkxAW0Eu",
    "outputId": "930d7ee5-88d9-41da-8a85-1d7110f5893c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data.....\n",
      "preprocessing data.....\n"
     ]
    }
   ],
   "source": [
    "features = [\"SUMMARY\", \"categories\", \"sub_categories\"]\n",
    "\n",
    "print(\"Loading data.....\")\n",
    "# noinspection PyInterpreter\n",
    "dataset = load_file(\"TextClassification_Data.csv\")\n",
    "data,target = dataset[features[0]].fillna(\" \"), dataset[features[1]]\n",
    "\n",
    "print(\"preprocessing data.....\")\n",
    "word_vectors = preprocess(data)\n",
    "\n",
    "trainingX,testX,trainingY,testY = train_test_split(word_vectors,target,test_size=0.4,random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "dZQ7-nARW0FA",
    "outputId": "b3e61c84-8d0b-4ec2-c5b2-5d885c175b9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning model.....\n",
      "Learning probablities for PRESCRIPTION\n",
      "Learning probablities for APPOINTMENTS\n",
      "Learning probablities for MISCELLANEOUS\n",
      "Learning probablities for ASK_A_DOCTOR\n",
      "Learning probablities for LAB\n"
     ]
    }
   ],
   "source": [
    "print(\"Learning model.....\")\n",
    "\n",
    "model = learn_model(trainingX,trainingY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "x_S7sqqfW0FN",
    "outputId": "22e64866-9772-4d20-9683-f3ca8c4a2dd5"
   },
   "outputs": [],
   "source": [
    "print(\"Classifying test data......\")      \n",
    "predictedY = classify(model, testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "fObDfWxfW0Fc",
    "outputId": "15b05bce-0ec4-4f8e-dd53-df384951da40"
   },
   "outputs": [],
   "source": [
    "print(\"Evaluating results.....\")\n",
    "evaluate(testY,predictedY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PZ-dmKn1W0F4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Q1_a (2).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
